import json
from pathlib import Path
from tqdm import tqdm

HUMAN_PROMPT_VALUE = """<video>
Watch this short video clip and respond with exactly one JSON object.

[Rules]
- The category must be either 'violence' or 'normal'.  
- Classify as violence if any of the following actions are present:  
  * Punching  
  * Kicking  
  * Weapon Threat
  * Weapon Attack
  * Falling/Takedown  
  * Pushing/Shoving  
  * Brawling/Group Fight  
- If none of the above are observed, classify as normal.  
- The following cases must always be classified as normal:  
  * Affection (hugging, holding hands, light touches)  
  * Helping (supporting, assisting)  
  * Accidental (unintentional bumping)  
  * Playful (non-aggressive playful contact)  

[Output Format]
- Output exactly one JSON object.  
- The object must contain only two keys: "category" and "description".  
- The description should briefly and objectively describe the scene.  

Example (violence):  
{"category":"violence","description":"A man in a black jacket punches another man, who stumbles backward."}

Example (normal):  
{"category":"normal","description":"Two people are hugging inside an elevator."}
"""


# --- ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: mode íŒŒë¼ë¯¸í„° ì¶”ê°€ ---
def create_final_dataset(root_dir: str, base_dir:str = "data/", mode: str = "train") -> list:
    """
    pathlibì„ ì‚¬ìš©í•´ ì§€ì •ëœ ë””ë ‰í† ë¦¬ì™€ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ì°¾ì•„
    ìš”ì²­ëœ ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        root_dir (str): JSONê³¼ ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬.
        base_dir (str): ìƒëŒ€ ê²½ë¡œ ê³„ì‚°ì„ ìœ„í•œ ê¸°ì¤€ ë””ë ‰í† ë¦¬.
        mode (str): ì²˜ë¦¬ ëª¨ë“œ ('train' ë˜ëŠ” 'test'). 
                     'test' ëª¨ë“œì—ì„œëŠ” human í”„ë¡¬í”„íŠ¸ë¥¼ ì œì™¸í•©ë‹ˆë‹¤.
    """
    final_dataset = []
    current_id = 0
    
    search_path = Path(root_dir)
    base_path = Path(base_dir)
    root_path = Path(root_dir)

    if not root_path.is_dir():
        print(f"ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ '{root_dir}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    print(f"'{root_dir}' ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ëª¨ë“œ: {mode})")
    
    json_files = list(root_path.rglob('*.json'))
    
    for json_path_obj in tqdm(json_files, desc="JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘"):
        try:
            with open(json_path_obj, 'r', encoding='utf-8') as f:
                data = json.load(f)

            category = None
            description = None

            if isinstance(data, dict):
                category = data.get("category")
                description = data.get("description")
            
            elif isinstance(data, list) and data:
                first_item = data[0]
                if isinstance(first_item, dict):
                    category = first_item.get("category")
                    description = first_item.get("eng_caption") or first_item.get("en_caption")

            if category is None or description is None:
                print(f"ê²½ê³ : '{json_path_obj}'ì— í•„ìˆ˜ í‚¤ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            video_stem = json_path_obj.stem
            video_path = None
            
            possible_files = list(json_path_obj.parent.glob(f"{video_stem}.*"))

            for file in possible_files:
                if file.suffix.lower() != '.json':
                    video_path = file
                    break 

            if not video_path:
                print(f"ê²½ê³ : '{json_path_obj}'ì— í•´ë‹¹í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            video_relative_path = video_path.relative_to(base_path).as_posix()
            gpt_value_dict = {
                "category": category,
                "description": description
            }
            gpt_value_string = json.dumps(gpt_value_dict, ensure_ascii=False)

            # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„ ì‹œì‘: modeì— ë”°ë¼ conversations êµ¬ì¡°ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì • ---
            conversations = []
            if mode == "test":
                # 'test' ëª¨ë“œì¼ ê²½ìš° 'gpt' ë¶€ë¶„ë§Œ ì¶”ê°€
                conversations.append({"from": "gpt", "value": gpt_value_string})
            else:
                # ê¸°ë³¸('train') ëª¨ë“œì¼ ê²½ìš° ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ 'human'ê³¼ 'gpt' ëª¨ë‘ ì¶”ê°€
                conversations.append({"from": "human", "value": HUMAN_PROMPT_VALUE})
                conversations.append({"from": "gpt", "value": gpt_value_string})
            # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„ ë ---

            item = {
                "id": current_id,
                "type": "clip",
                "task": "caption",
                "video": video_relative_path,
                # 'conversations' í‚¤ì— ìœ„ì—ì„œ ìƒì„±í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ í• ë‹¹
                "conversations": conversations
            }
            final_dataset.append(item)
            current_id += 1

        except json.JSONDecodeError:
            print(f"ê²½ê³ : '{json_path_obj}'ëŠ” ì˜¬ë°”ë¥¸ JSON íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì˜¤ë¥˜: '{json_path_obj}' ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    return final_dataset

# --- ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: mode íŒŒë¼ë¯¸í„° ì¶”ê°€ ---
def label_to_jsonl_result_save(input_dir, output_file_path, mode="train", base_dir="data/" ):
    # create_final_dataset í•¨ìˆ˜ í˜¸ì¶œ ì‹œ mode ì¸ì ì „ë‹¬
    my_dataset = create_final_dataset(input_dir, base_dir, mode=mode)
    if my_dataset:
            try:
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    for entry in tqdm(my_dataset, desc="JSONL íŒŒì¼ ì €ì¥ ì¤‘"):
                        f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                
                print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(my_dataset)}ê°œì˜ í•­ëª©ì„ '{output_file_path}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜: '{output_file_path}' íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print(f"\nì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ê²½ë¡œ '{input_dir}'ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ë¶€ë¶„ ---
if __name__ == '__main__':
    input_directory = "data"  
    output_file_path = "final_dataset.jsonl"
    
    # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„: ì²˜ë¦¬ ëª¨ë“œ ì„¤ì • ---
    # 'test'ë¡œ ì„¤ì •í•˜ë©´ human íŒŒíŠ¸ê°€ ì œì™¸ë©ë‹ˆë‹¤.
    # ê¸°ì¡´ì²˜ëŸ¼ human íŒŒíŠ¸ë¥¼ í¬í•¨í•˜ë ¤ë©´ 'train'ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    processing_mode = "test" 
    
    # í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì„¤ì •í•œ modeë¥¼ ì „ë‹¬
    label_to_jsonl_result_save(input_directory, output_file_path, mode=processing_mode)

    