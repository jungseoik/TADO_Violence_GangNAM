import json
from pathlib import Path
from tqdm import tqdm

HUMAN_PROMPT_VALUE = """<video>
Watch this short video clip and respond with exactly one JSON object.

[Rules]
- The category must be either 'violence' or 'normal'.  
- Classify as violence if any of the following actions are present:  
  * Punching  
  * Kicking  
  * Weapon Threat
  * Weapon Attack
  * Falling/Takedown  
  * Pushing/Shoving  
  * Brawling/Group Fight  
- If none of the above are observed, classify as normal.  
- The following cases must always be classified as normal:  
  * Affection (hugging, holding hands, light touches)  
  * Helping (supporting, assisting)  
  * Accidental (unintentional bumping)  
  * Playful (non-aggressive playful contact)  

[Output Format]
- Output exactly one JSON object.  
- The object must contain only two keys: "category" and "description".  
- The description should briefly and objectively describe the scene.  

Example (violence):  
{"category":"violence","description":"A man in a black jacket punches another man, who stumbles backward."}

Example (normal):  
{"category":"normal","description":"Two people are hugging inside an elevator."}
"""
HUMAN_PROMPT_VALUE_FALLDOWN = """<image>
Analyze this image carefully. Determine if a person has fallen down.

Important classification rules:

- The "falldown" category applies to any person who is lying down, regardless of:
  - the surface (e.g., floor, mattress, bed)
  - the posture (natural or unnatural)
  - the cause (e.g., sleeping, collapsing, lying intentionally)
- This includes:
  - A person lying flat on the ground or other surfaces
  - A person collapsed or sprawled in any lying position
- The "normal" category applies only if the person is:
  - sitting
  - standing
  - kneeling
  - or otherwise upright (not lying down)

Answer in JSON format with BOTH of the following fields:
- "category": either "falldown" or "normal"
- "description": a brief reason why this classification was made (e.g., "person lying on a mattress", "person sitting on sofa")

Example:
{ 
  "category": "falldown", 
  "description": "person lying on a mattress in natural posture" 
}
"""



def create_final_dataset(root_dir: str, base_dir:str = "data/", mode: str = "train",
                         data_type: str = "video") -> list:
    """
    pathlibì„ ì‚¬ìš©í•´ ì§€ì •ëœ ë””ë ‰í† ë¦¬ì™€ ëª¨ë“  í•˜ìœ„ ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ì„ ì¬ê·€ì ìœ¼ë¡œ ì°¾ì•„
    ìš”ì²­ëœ ìµœì¢… ë°ì´í„°ì…‹ êµ¬ì¡°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        root_dir (str): JSONê³¼ ë¹„ë””ì˜¤ íŒŒì¼ì´ ìˆëŠ” ë£¨íŠ¸ ë””ë ‰í† ë¦¬.
        base_dir (str): ìƒëŒ€ ê²½ë¡œ ê³„ì‚°ì„ ìœ„í•œ ê¸°ì¤€ ë””ë ‰í† ë¦¬.
        mode (str): ì²˜ë¦¬ ëª¨ë“œ ('train' ë˜ëŠ” 'test'). 'test' ëª¨ë“œì—ì„œëŠ” human í”„ë¡¬í”„íŠ¸ë¥¼ ì œì™¸í•©ë‹ˆë‹¤.
        data_type (str): 'video' ë˜ëŠ” 'image' ì„ íƒ
    """
    final_dataset = []
    current_id = 0
    
    search_path = Path(root_dir)
    base_path = Path(base_dir)
    root_path = Path(root_dir)

    if not root_path.is_dir():
        print(f"ì˜¤ë¥˜: ë””ë ‰í† ë¦¬ '{root_dir}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return []

    print(f"'{root_dir}' ë””ë ‰í† ë¦¬ì—ì„œ JSON íŒŒì¼ íƒìƒ‰ì„ ì‹œì‘í•©ë‹ˆë‹¤... (ëª¨ë“œ: {mode})")
    
    json_files = list(root_path.rglob('*.json'))
    
    for json_path_obj in tqdm(json_files, desc="JSON íŒŒì¼ ì²˜ë¦¬ ì¤‘"):
        try:
            with open(json_path_obj, 'r', encoding='utf-8') as f:
                data = json.load(f)

            category = None
            description = None

            if isinstance(data, dict):
                category = data.get("category")
                description = data.get("description")
            
            elif isinstance(data, list) and data:
                first_item = data[0]
                if isinstance(first_item, dict):
                    category = first_item.get("category")
                    description = first_item.get("eng_caption") or first_item.get("en_caption")

            if category is None or description is None:
                print(f"ê²½ê³ : '{json_path_obj}'ì— í•„ìˆ˜ í‚¤ê°€ ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")
                continue

            video_stem = json_path_obj.stem
            # video_path = None
            
            possible_files = list(json_path_obj.parent.glob(f"{video_stem}.*"))
            media_path = None
            
            for file in possible_files:
                if file.suffix.lower() != '.json':
                    if data_type == "video" and file.suffix.lower() in [".mp4", ".avi", ".mov", ".mkv"]:
                        media_path = file
                        break
                    elif data_type == "image" and file.suffix.lower() in [".jpg", ".jpeg", ".png", ".bmp", ".webp"]:
                        media_path = file
                        break
                    # video_path = file
                    # break 

            if not media_path:
                print(f"ê²½ê³ : '{json_path_obj}'ì— í•´ë‹¹í•˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
                continue
            
            # video_relative_path = video_path.relative_to(base_path).as_posix()
            
            gpt_value_dict = {
                "category": category,
                "description": description
            }
            gpt_value_string = json.dumps(gpt_value_dict, ensure_ascii=False)

            # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„ ì‹œì‘: modeì— ë”°ë¼ conversations êµ¬ì¡°ë¥¼ ë‹¤ë¥´ê²Œ ì„¤ì • ---
            conversations = []
            if mode == "test":
                # 'test' ëª¨ë“œì¼ ê²½ìš° 'gpt' ë¶€ë¶„ë§Œ ì¶”ê°€
                conversations.append({"from": "gpt", "value": gpt_value_string})
            else:
                if data_type == "video":
                # ê¸°ë³¸('train') ëª¨ë“œì¼ ê²½ìš° ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ 'human'ê³¼ 'gpt' ëª¨ë‘ ì¶”ê°€
                    conversations.append({"from": "human", "value": HUMAN_PROMPT_VALUE})
                    conversations.append({"from": "gpt", "value": gpt_value_string})
                elif data_type == "image":
                    conversations.append({"from": "human", "value": HUMAN_PROMPT_VALUE_FALLDOWN})
                    conversations.append({"from": "gpt", "value": gpt_value_string})
                    
            # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„ ë ---
            media_relative_path = media_path.relative_to(base_path).as_posix()
            if data_type == "video":
                item = {
                    "id": current_id,
                    "type": "clip",
                    "task": "caption",
                    "video": media_relative_path,
                    "conversations": conversations
                }
            elif data_type == "image":
                item = {
                    "id": current_id,
                    "type": "capture_frame",
                    "task": "caption",
                    "image": media_relative_path,
                    "conversations": conversations
                }
            
            # item = {
            #     "id": current_id,
            #     "type": "clip",
            #     "task": "caption",
            #     "video": video_relative_path,
            #     # 'conversations' í‚¤ì— ìœ„ì—ì„œ ìƒì„±í•œ ë¦¬ìŠ¤íŠ¸ë¥¼ í• ë‹¹
            #     "conversations": conversations
            # }
            final_dataset.append(item)
            current_id += 1

        except json.JSONDecodeError:
            print(f"ê²½ê³ : '{json_path_obj}'ëŠ” ì˜¬ë°”ë¥¸ JSON íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        except Exception as e:
            print(f"ì˜¤ë¥˜: '{json_path_obj}' ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    return final_dataset

# --- ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: mode íŒŒë¼ë¯¸í„° ì¶”ê°€ ---
def label_to_jsonl_result_save(input_dir, output_file_path, mode="train", data_type="video", base_dir="data/" ):
    # create_final_dataset í•¨ìˆ˜ í˜¸ì¶œ ì‹œ mode ì¸ì ì „ë‹¬
    my_dataset = create_final_dataset(input_dir, base_dir, mode=mode, data_type=data_type)
    if my_dataset:
            try:
                with open(output_file_path, 'w', encoding='utf-8') as f:
                    for entry in tqdm(my_dataset, desc="JSONL íŒŒì¼ ì €ì¥ ì¤‘"):
                        f.write(json.dumps(entry, ensure_ascii=False) + '\n')
                
                print(f"\nâœ… ì²˜ë¦¬ ì™„ë£Œ! ì´ {len(my_dataset)}ê°œì˜ í•­ëª©ì„ '{output_file_path}' íŒŒì¼ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            except Exception as e:
                print(f"\nâŒ ì˜¤ë¥˜: '{output_file_path}' íŒŒì¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
        print(f"\nì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì…ë ¥ ê²½ë¡œ '{input_dir}'ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")

# --- ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì§ì ‘ ì‹¤í–‰í•  ë•Œ ì‚¬ìš©ë˜ëŠ” ë¶€ë¶„ ---
if __name__ == '__main__':
    input_directory = "data"  
    output_file_path = "final_dataset.jsonl"
    
    # --- ğŸ’¡ ì¶”ê°€ëœ ë¶€ë¶„: ì²˜ë¦¬ ëª¨ë“œ ì„¤ì • ---
    # 'test'ë¡œ ì„¤ì •í•˜ë©´ human íŒŒíŠ¸ê°€ ì œì™¸ë©ë‹ˆë‹¤.
    # ê¸°ì¡´ì²˜ëŸ¼ human íŒŒíŠ¸ë¥¼ í¬í•¨í•˜ë ¤ë©´ 'train'ìœ¼ë¡œ ì„¤ì •í•˜ì„¸ìš”.
    processing_mode = "test" 
    
    # í•¨ìˆ˜ í˜¸ì¶œ ì‹œ ì„¤ì •í•œ modeë¥¼ ì „ë‹¬
    label_to_jsonl_result_save(input_directory, output_file_path, mode=processing_mode)

    