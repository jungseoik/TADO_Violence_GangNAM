import argparse
import json
import sys
from collections import Counter
from typing import Any, Dict, Iterable, Optional, Union, List
from pathlib import Path

def remove_human_video_prompts(jsonl_path, output_path=None):
    """
    JSONL íŒŒì¼ì—ì„œ {"from": "human", "value": "<video>..."} í˜•íƒœì˜ ëŒ€í™”ë§Œ ì‚­ì œí•˜ê³  ë‹¤ì‹œ ì €ì¥
    
    Args:
        jsonl_path (str): ì›ë³¸ JSONL íŒŒì¼ ê²½ë¡œ
        output_path (str, optional): ìˆ˜ì •ëœ JSONL ì €ì¥ ê²½ë¡œ (Noneì´ë©´ ì›ë³¸ íŒŒì¼ ë®ì–´ì”€)
    """
    if output_path is None:
        output_path = jsonl_path  # ì›ë³¸ ë®ì–´ì“°ê¸°

    new_lines = []
    with open(jsonl_path, "r", encoding="utf-8") as f:
        for line in f:
            if not line.strip():
                continue
            obj = json.loads(line)

            if "conversations" in obj:
                # "human" + "<video>" í”„ë¡¬í”„íŠ¸ ì œê±°
                obj["conversations"] = [
                    conv for conv in obj["conversations"]
                    if not (conv.get("from") == "human" and conv.get("value", "").startswith("<video>"))
                ]
            new_lines.append(obj)

    # ë‹¤ì‹œ ì €ì¥
    with open(output_path, "w", encoding="utf-8") as f:
        for obj in new_lines:
            f.write(json.dumps(obj, ensure_ascii=False) + "\n")

    print(f"âœ… ì €ì¥ ì™„ë£Œ: {output_path}")
# ============================================
# JSONL ë¶„ì„ í•¨ìˆ˜ë“¤
# ============================================

def load_jsonl(file_path: str) -> List[Dict[str, Any]]:
    """JSONL íŒŒì¼ì„ ì½ì–´ì„œ dict ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line_no, line in enumerate(f, 1):
            line = line.strip()
            if not line:
                continue
            try:
                data.append(json.loads(line))
            except json.JSONDecodeError as e:
                print(f"âš ï¸  Line {line_no}: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}")
    return data


def parse_json_value(value: Any) -> Optional[Dict[str, Any]]:
    """ë¬¸ìì—´ì„ JSONìœ¼ë¡œ íŒŒì‹±, ì´ë¯¸ dictë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜"""
    if isinstance(value, dict):
        return value
    
    if isinstance(value, str):
        try:
            parsed = json.loads(value.strip())
            return parsed if isinstance(parsed, dict) else None
        except (json.JSONDecodeError, AttributeError):
            return None
    
    return None


def extract_category(item: Dict[str, Any]) -> Optional[str]:
    """
    í•œ ë ˆì½”ë“œì—ì„œ ë§ˆì§€ë§‰ gpt ì‘ë‹µì˜ category ì¶”ì¶œ
    
    Returns:
        category ë¬¸ìì—´ (ì†Œë¬¸ì) ë˜ëŠ” None
    """
    conversations = item.get('conversations')
    if not isinstance(conversations, list):
        return None
    
    gpt_messages = [
        msg for msg in conversations 
        if isinstance(msg, dict) and msg.get('from') == 'gpt'
    ]
    
    if not gpt_messages:
        return None
    
    # ë§ˆì§€ë§‰ gpt ë©”ì‹œì§€ë¶€í„° ì—­ìˆœìœ¼ë¡œ íƒìƒ‰
    for msg in reversed(gpt_messages):
        parsed = parse_json_value(msg.get('value'))
        if parsed and 'category' in parsed:
            return str(parsed['category']).strip().lower()
    
    return None


def get_category_distribution(data: List[Dict[str, Any]]) -> Dict[str, int]:
    """ë°ì´í„°ì…‹ì˜ category ë¶„í¬ ì§‘ê³„"""
    categories = []
    
    for item in data:
        cat = extract_category(item)
        if cat:
            categories.append(cat)
    
    return dict(Counter(categories))


def _print_single_stats(file_path: str, stats: Dict[str, int], total: int) -> None:
    """ë‹¨ì¼ íŒŒì¼ì˜ í†µê³„ ì¶œë ¥ (ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜)"""
    valid_count = sum(stats.values())
    
    print(f"\nğŸ“„ {Path(file_path).name}")
    print(f"{'â”€'*60}")
    print(f"  ì´ ìƒ˜í”Œ: {total:,}ê°œ  |  ìœ íš¨: {valid_count:,}ê°œ")
    print(f"{'â”€'*60}")
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì¶œë ¥ (ë¹ˆë„ìˆœ)
    for cat, count in sorted(stats.items(), key=lambda x: x[1], reverse=True):
        pct = (count / valid_count * 100) if valid_count > 0 else 0
        print(f"    {cat:15s}: {count:7,}ê°œ  ({pct:6.2f}%)")
    
    # ëˆ„ë½ëœ ìƒ˜í”Œ
    missing = total - valid_count
    if missing > 0:
        print(f"  âš ï¸  Category ëˆ„ë½: {missing:,}ê°œ")


def print_dataset_info(file_paths: Union[str, List[str]]) -> None:
    """
    JSONL ë°ì´í„°ì…‹ì˜ ì •ë³´ ì¶œë ¥
    
    Args:
        file_paths: JSONL íŒŒì¼ ê²½ë¡œ (ë‹¨ì¼ ë¬¸ìì—´ ë˜ëŠ” ë¦¬ìŠ¤íŠ¸)
    """
    # ë‹¨ì¼ íŒŒì¼ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    if isinstance(file_paths, str):
        file_paths = [file_paths]
    
    print(f"\n{'='*60}")
    print(f"ğŸ“Š Dataset Analysis")
    print(f"{'='*60}")
    
    # ê° íŒŒì¼ë³„ ë°ì´í„° ìˆ˜ì§‘
    all_data = []
    file_stats = []
    
    for file_path in file_paths:
        data = load_jsonl(file_path)
        stats = get_category_distribution(data)
        
        all_data.extend(data)
        file_stats.append({
            'path': file_path,
            'data': data,
            'stats': stats,
            'total': len(data)
        })
    
    # 1. ê°œë³„ íŒŒì¼ ì •ë³´ ì¶œë ¥
    if len(file_paths) > 1:
        print(f"\n[ ê°œë³„ íŒŒì¼ ì •ë³´ ]")
        for fs in file_stats:
            _print_single_stats(fs['path'], fs['stats'], fs['total'])
    
    # 2. ì „ì²´ í†µí•© ì •ë³´ ì¶œë ¥
    if len(file_paths) > 1:
        print(f"\n{'='*60}")
        print(f"ğŸ“Š ì „ì²´ í†µí•© í†µê³„")
        print(f"{'='*60}")
    
    total_samples = len(all_data)
    total_stats = get_category_distribution(all_data)
    valid_count = sum(total_stats.values())
    
    print(f"\nì´ íŒŒì¼ ìˆ˜: {len(file_paths)}ê°œ")
    print(f"ì´ ìƒ˜í”Œ ìˆ˜: {total_samples:,}ê°œ")
    print(f"ìœ íš¨ ìƒ˜í”Œ: {valid_count:,}ê°œ")
    
    print(f"\n{'â”€'*60}")
    print(f"Category ë¶„í¬")
    print(f"{'â”€'*60}")
    
    # ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì¶œë ¥ (ë¹ˆë„ìˆœ)
    for cat, count in sorted(total_stats.items(), key=lambda x: x[1], reverse=True):
        pct = (count / valid_count * 100) if valid_count > 0 else 0
        print(f"  {cat:15s}: {count:7,}ê°œ  ({pct:6.2f}%)")
    
    # ëˆ„ë½ëœ ìƒ˜í”Œ
    missing = total_samples - valid_count
    if missing > 0:
        print(f"\nâš ï¸  Category ëˆ„ë½: {missing:,}ê°œ")
    
    print(f"{'='*60}\n")


def get_dataset_summary(file_path: str) -> Dict[str, Any]:
    """
    ë°ì´í„°ì…‹ ìš”ì•½ ì •ë³´ë¥¼ dictë¡œ ë°˜í™˜
    
    Returns:
        {
            'total_samples': int,
            'valid_samples': int,
            'missing_samples': int,
            'categories': {'category': count, ...}
        }
    """
    data = load_jsonl(file_path)
    stats = get_category_distribution(data)
    
    total = len(data)
    valid = sum(stats.values())
    
    return {
        'total_samples': total,
        'valid_samples': valid,
        'missing_samples': total - valid,
        'categories': stats
    }


if __name__ == "__main__":
    print_dataset_info("data/instruction/train/train_abb_vqa.jsonl")
    # remove_human_video_prompts("data/instruction/train/train_abb_vqa_train.jsonl")
